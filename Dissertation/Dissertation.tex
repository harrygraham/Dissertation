\documentclass[12pt,a4paper,twoside]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage[margin=25mm]{geometry}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{enumerate}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

% For temporarily splitting the document into multiple columns
\usepackage{multicol}

% Command for extracting the word count.
\newcommand\wordcount{\input{word.count}}

\begin{document}

% Title Page
\begin{titlepage}
	\noindent
	\begin{minipage}[t][][t]{0.5\textwidth}
		\includegraphics[width=40mm]{CamLogo.jpg}
	\end{minipage}
	\begin{minipage}{0.5\textwidth}
	\begin{flushright}
		\large
		\textit{Harry Graham}
		\\
		\textit{Christ's College}
		\\
		\texttt{hg402}
	\end{flushright}
	\end{minipage}
	
	\begin{center}
	\vspace{6cm}
	{\sc\large Computer Science Tripos - Part II Project\par}
	\vspace{0.5cm}
	{\huge\bf Deep Learning Techniques for Credit Card Fraud Detection\par}
	\vspace{0.5cm}
	{\large May 18, 2018 \par}
	\end{center}

\end{titlepage}

\pagestyle{plain}

\section*{\huge Proforma}
\vspace{0.5cm}
{\large
\begin{tabular}{ll}
Name:               & \bf Harry Graham \\
College:            & \bf Christ's College \\
Project Title:      & \bf Deep Learning Techniques for Credit Card Fraud \\
			 & \bf Detection \\
Examination:        & \bf Computer Science Tripos -- Part II, June 2018 \\
Word Count:         &  \\
Project Originators: & H.~Graham \& B.~Dimanov \\
Supervisors:         & Dr M.~Jamnik \& B.~Dimanov 
\end{tabular}
}

\section*{Original Aims of the Project}
The primary aim of the project was to implement and compare some deep learning techniques, alongside some baseline models, for credit card fraud detection (CCFD). More specifically, I aimed to experiment with two popular types of architecture, namely Convolutional Neural Networks (CNNs)  \cite{DBLP:journals/corr/SimonyanZ14a} and Generative Adversarial Networks (GANs). These have been successful in the image classification space and the aim of this project was to shed light on their use in the credit card fraud space. This kind of experimentation of predominantly image-based models, on single dimensional, time-series data is a relatively novel approach for CCFD.

\section*{Work Completed}
All of the core project aims set out in the proposal have been met, meaning results have been collated and evaluated across the three main components of the project: Baseline Models, CNN methods and GAN methods. 
I have also gone on to do some extension work relating to further investigation on the models I have experimented with. This is in the form of parameter tuning and further analysis not originally set out in the project proposal.

\section*{Special Difficulties}
None.


\newpage
\section*{Declaration}

I, Harry Graham of Christ's College, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial extent for a comparable purpose.

\vspace{1cm}
\begin{multicols}{2}

\rule{5cm}{0.15mm} \\
\leftline{\scshape{Signed}}

\columnbreak

\rule{5cm}{0.15mm} \\
\leftline{\scshape{Date}}

\end{multicols}


\tableofcontents

\pagestyle{headings} % TODO: fancyhdr - make chapter name -- section appear in headers

%%
%\usepackage{fancyhdr}
%\pagestyle{fancy}
%\fancyhf{} % clear the headers
%
%\fancyfoot[L]{\thechapter \thesection}
%%

\chapter{Introduction}

Credit card fraud is a globally significant and increasing problem. According to the Nilson Report \cite{nilsonreport}, annual global fraud losses reached \$22.80 billion in 2016, up 4.4\% over 2015. Machine learning has contributed a lot to this problem over the years, helping to automatically learn to classify fraudulent transactions. However, this is still somewhat tedious and clearly, the money lost due to fraud is not decreasing. Not to mention, we still have this difficult business decision of when to draw the cutoff points between classifying fraud but perhaps allowing more benign transactions to be blocked.

A lot of machine learning concepts have been around for decades but ongoing research into deep learning architectures and their applications, makes for an interesting experimentation space. In this project I explore the performance of some particular models, focusing on deep learning, applied to the particular problem of credit card fraud detection (CCFD).

In particular, the aim is to shed light on the use of architectures that have had success in the image classification/generation space, in the context of non-image data i.e transactional vectors and time series data.
This is something that has recently seen some success \cite{wang2017time} and is novel to credit card fraud data. 
I first explore a set of baseline classifiers, which are primarily a handful of out-of-the-box supervised learning classifiers such as Random Forest. The point of these is to set the scene for experimenting with the data and to see what can be achieved with what is easily available, in other words without any 'deep' learning components. Here, I also establish techniques and methods for processing and evaluating the data i.e cross-validation, datapoint scaling, and data visualisation. 

Then the project shifts to experimenting with Convolutional Neural Networks (CNNs) \cite{DBLP:journals/corr/SimonyanZ14a} and Generative Adversarial Networks (GANs) \cite{2014arXiv1406.2661G}.  

\chapter{Preparation} \label{preparation}

\section{Software Engineering}

This section details the project requirements and early design decisions that were made.

\subsection{Tools and Technologies Used} \label{tools}

Below I describe and justify where necessary the tools and technologies that I used.

\subsubsection{Version Control and Project Tools}

I hosted my project in a repository on GitHub\footnote{\href{https://github.com/harrygraham/DeepLearning-CreditCardFraud}{https://github.com/harrygraham/DeepLearning-CreditCardFraud}}, used Git for version control, and used virtual environments with pip for project package management and requirements.

I made heavy use of Jupyter Notebooks for writing code in an experimental manner, with immediate execution and feedback. 

I implemented work predominately making use of Keras\footnote{\href{https://keras.io}{https://keras.io}}(with TensorFlow\footnote{\href{https://www.tensorflow.org}{https://www.tensorflow.org}} backend) for CNN and GAN work and SciKit-Learn\footnote{\href{ http://scikit-learn.org/stable/}{ http://scikit-learn.org/stable/}} for baseline models and some general data manipulation/metric functions. 

\subsubsection{Languages}

My project was entirely written in Python, using the libraries and APIs described previously. This is mainly due to the large ecosystem and documentation surrounding these machine learning libraries in python and also for the ease of use of tools such as Jupyter Notebooks for experimentation.

\subsection{Starting Point}

My project codebase was written from scratch, with the assistance of the tools and libraries mentioned above. Apart from a basic knowledge


\chapter{Implementation}

\chapter{Evaluation}

\chapter{Conclusions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\newpage
\addcontentsline{toc}{chapter}{Bibliography}
\bibliographystyle{ieeetr}
\bibliography{references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}





